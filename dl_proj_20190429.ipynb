{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CagIRWxBQTnM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1557856021364,
     "user": {
      "displayName": "Kimmo Mikkola",
      "photoUrl": "https://lh6.googleusercontent.com/-vEKdWCQ-jLw/AAAAAAAAAAI/AAAAAAAADzo/T6IFF32mx_s/s64/photo.jpg",
      "userId": "13341027390448675707"
     },
     "user_tz": -180
    },
    "id": "TS0q5u_RQTnO",
    "outputId": "bd34840f-53cc-44f7-ab7d-a2be9757fede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# Use the GPU if there is one, otherwise CPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    device = torch.device('cuda:0')\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lnyj_NQfQTno"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(net, testloader, conf=False):\n",
    "    # Set the network into evaluation mode\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    classes = 5\n",
    "    \n",
    "    # Initialize the confusion matrix\n",
    "    confusion_matrix = torch.zeros(classes, classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # We're assuming batch size of 10 in testloader\n",
    "            zeros += (predicted == torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]).to(device)).sum().item()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Calculate the confusion matrix if requested\n",
    "            if conf:\n",
    "                for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "    \n",
    "    # Print the confusion matrix if requested\n",
    "    if conf:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(confusion_matrix)\n",
    "        print(\"Per-class accuracy\")\n",
    "        print(confusion_matrix.diag()/confusion_matrix.sum(1))\n",
    "        \n",
    "    # Return the amount of predicted zeros and the accuracy\n",
    "    return zeros, (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA7hagRNQTnw"
   },
   "outputs": [],
   "source": [
    "class DatasetDRD(Dataset):\n",
    "    def __init__(self, csv_path, data_folder, prefix):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data_folder = data_folder\n",
    "        self.prefix = prefix\n",
    "        \n",
    "        # Transform to tensor\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Check that the files actually exist\n",
    "        assert self.data_info['image'].apply(lambda x: os.path.isfile(self.data_folder\n",
    "                                                                      + '/' + self.prefix + x + '.jpeg')).all(), \\\n",
    "        \"Some images referenced in the CSV file were not found\"\n",
    "        \n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        \n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        \n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = Image.open(self.data_folder + '/' + self.prefix + single_image_name + '.jpeg')\n",
    "\n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-MoT_5ZQToK"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False, stride=stride)\n",
    "        self.batch1 = nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch2 = nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.skipconv = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False, stride=stride)\n",
    "        self.skipbatch = nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # Detect possible skip connection with conv2d and batchnorm\n",
    "        self.inout = True if in_channels != out_channels else False\n",
    "\n",
    "    def forward(self, x):\n",
    "        skipout = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.batch1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.batch2(out)\n",
    "        \n",
    "        # Perform the actual skip connection with conv2d and batchnorm\n",
    "        if (self.stride != 1 or self.inout):\n",
    "            skipout = self.skipconv(skipout)\n",
    "            skipout = self.skipbatch(skipout)\n",
    "        \n",
    "        out += skipout\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_XQzru8QToM"
   },
   "outputs": [],
   "source": [
    "class GroupOfBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_blocks, stride=1):\n",
    "        super(GroupOfBlocks, self).__init__()\n",
    "        \n",
    "        # First block stride can be defined to be something but the default\n",
    "        first_block = Block(in_channels, out_channels, stride)\n",
    "        # The rest of the blocks have stride as one\n",
    "        other_blocks = [Block(out_channels, out_channels) for _ in range(1, n_blocks)]\n",
    "        self.group = nn.Sequential(first_block, *other_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.group(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtO3JT2MQToO"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_blocks, n_channels=16, num_classes=5):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        # Layers before blocks\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=n_channels, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Create the group of blocks with desired settings depending on blocks location withing group\n",
    "        self.groupblocks = [GroupOfBlocks(\n",
    "            in_channels=n_channels * (2**(0 if (idx-1) == -1 else (idx-1))),\n",
    "            out_channels=n_channels * 2**(idx),\n",
    "            n_blocks=x,\n",
    "            stride=1 if idx == 0 else 2)\n",
    "                            for idx, x in enumerate(n_blocks)]\n",
    "        self.groupb = nn.Sequential(*self.groupblocks)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4, stride=1)\n",
    "        self.fc = nn.Linear(20736*n_channels, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        # Initial layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # \"Group of blocks\"\n",
    "        x = self.groupb(x)\n",
    "\n",
    "        # The global average pool\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        # Reshape the tensor for the final linear layer\n",
    "        x = x.view(-1, self.fc.in_features)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRolneVfxNp5"
   },
   "outputs": [],
   "source": [
    "# Note: All the training and testing were performed in Google Colaboratory\n",
    "#           so it is not possible to test the network here.\n",
    "\n",
    "# The folders and csv files can't be found in Github for obvious reasons\n",
    "data_drd = DatasetDRD(csv_path='train5k.csv.mod.rot', data_folder='rtrain5k', prefix='600_600_300_')\n",
    "test_drd = DatasetDRD(csv_path='test1k.csv.mod', data_folder='test1k', prefix='600_600_300_')\n",
    "\n",
    "# Set up the loaders for training and testing\n",
    "trainloader = torch.utils.data.DataLoader(data_drd, batch_size=10, shuffle=True, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(test_drd, batch_size=10, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67579,
     "status": "error",
     "timestamp": 1557845526925,
     "user": {
      "displayName": "Kimmo Mikkola",
      "photoUrl": "https://lh6.googleusercontent.com/-vEKdWCQ-jLw/AAAAAAAAAAI/AAAAAAAADzo/T6IFF32mx_s/s64/photo.jpg",
      "userId": "13341027390448675707"
     },
     "user_tz": -180
    },
    "id": "kvxvBtT-nwV6",
    "outputId": "a0f4a204-4fab-4556-fe44-91e1348252da"
   },
   "outputs": [],
   "source": [
    "# The parameters for the selected architecture\n",
    "n_blocks = [4, 4, 5]\n",
    "lr_rand = 0.00001\n",
    "n_channels = 16\n",
    "\n",
    "# Debug info\n",
    "print(\"Running round with architecture: {}, learning rate: {}, n_channels: {}\".format(n_blocks, lr_rand, n_channels))\n",
    "\n",
    "# Initialize the network and move it to the device\n",
    "net = ResNet(n_blocks, n_channels=n_channels)\n",
    "net.to(device)\n",
    "\n",
    "# Set up the criterion (CrossEntropyLoss) and optimizer (Adam)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr_rand)\n",
    "\n",
    "# Train for 10 rounds\n",
    "n_epochs = 10\n",
    "\n",
    "# Set the network to training mode and start training\n",
    "net.train()\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200  # mini-batches\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        # Transfer to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1):\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Get the accuracy of the network, prints also the confusion matrix\n",
    "    _, accuracy = compute_accuracy(net, testloader, conf=True)\n",
    "    print('Accuracy of the network on the test images: {:.4f}'.format(accuracy))\n",
    "\n",
    "print('Training done!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dl_proj_20190429.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
